<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="Project page of CORING">
    <meta property="og:title" content="Efficient tensor decomposition-based filter pruning" />
    <meta property="og:description"
        content="Project page of the Neural Networks paper Efficient tensor decomposition-based filter pruning" />
    <meta property="og:url" content="https://pvtien96.github.io/coring-project-page/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/images/banner.png" />
    <meta property="og:image:width" content="128" />
    <meta property="og:image:height" content="120" />
    
    
    <meta name="twitter:title" content="Project page of CORING">
    <meta name="twitter:description"
        content="Project page of the Neural Networks paper Efficient tensor decomposition-based filter pruning">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/banner.png">
    <meta name="twitter:card" content="static/images/overview.png">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="CORING">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    
    <title>Efficient Tensor Decomposition-based Filter Pruning</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    </head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Efficient Tensor Decomposition-based Filter Pruning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/pvtien96" target="_blank">Van Tien Pham</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://yzniyed.blogspot.com/p/about-me.html" target="_blank">Yassine Zniyed,</span>
                  <span class="author-block">
                    <a href="http://tpnguyen.univ-tln.fr/" target="_blank">Thanh Phuong Nguyen</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Université de Toulon, Aix Marseille Université, CNRS, LIS, UMR 7020, France<br>Neural Networks</span>
                    <span class="eql-cntrb"><small><sup>*</sup>Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://hal.science/hal-04475150v1/file/gretsi2023.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/pvtien96/CORING" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/ring.png" alt="overview" />
      <h2 class="subtitle has-text-centered">
        One model to compress them all, one approach to refine efficiency,
        One method to decompose tensors and enhance neural proficiency.
        In the realm of filters, CORING stands tall and true,
        Preserving dimensions, accuracy it will accrue.
        Experiments demonstrate its prowess, architectures put to test,
        FLOPS and parameters reduced, accuracy manifest.
        Like ResNet-50 in ImageNet's vast domain,
        Memory and computation requirements it does restrain.
        Efficiency elevated, generalization takes its flight,
        In the world of neural networks, C:ring:RING shines its light.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, we present CORING, which is short for effiCient tensOr decomposition-based filteR prunING, a novel filter pruning methodology for neural networks. CORING is crafted to achieve efficient tensor decomposition-based pruning, a stark departure from conventional approaches that rely on vectorized or matricized filter representations. Our approach represents a significant leap forward in the field by introducing tensor decompositions, specifically the HOSVD, which preserves the multidimensional nature of filters while providing a low-rank approximation, thus substantially reducing complexity. Furthermore, we introduce a versatile method for calculating filter similarity by using the low-rank approximation offered by the HOSVD. This obviates the need for using full filters or reshaped versions and enhances the overall efficiency and effectiveness of our approach. Extensive experimentation across diverse architectures and datasets spanning various vision tasks, including image classification, object detection, instance segmentation, and keypoint detection, validates CORING's prowess. Remarkably, it outperforms state-of-the-art methods in reducing MACs and parameters, consistently enhancing validation accuracy. Furthermore, we supplement our quantitative results with a comprehensive ablation study, providing substantial evidence of the efficiency of our tensor-based approach. Beyond quantitative outcomes, qualitative results vividly illustrate CORING's ability to retain essential features within pruned neural networks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


  <!-- Method overview -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Methodology</h2>
        <img src="static/images/overview.png" alt="overview" />
        <p class="content has-text-justified">
          The CORING approach for filter pruning in one layer.
        </p>
      </div>
    </div>
    </div>
  </section>
  <!-- End method overview -->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/poster.pdf" width="100%" height="100%">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{pham2024efficient,
          title={Efficient tensor-based filter pruning}, 
          author={Van Tien, Pham and Yassine, Zniyed and Thanh Phuong, Nguyen},
          journal={Neural Networks},
          year={2024}
          }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


 <!--Acknowledgements-->
 <section class="section" id="acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      This work was granted access to the HPC resources of IDRIS under the allocation 2023-103147 made by GENCI. The work of T.P. Nguyen is partially supported by ANR ASTRID ROV-Chasseur.
    </p>
  </div>
</section>
<!--End Acknowledgements-->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
